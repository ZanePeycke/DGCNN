{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElZajgEwPutn"
   },
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zHdY994fZ52"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-plmmlw8m/dlib/dlib/cuda/gpu_data.cpp:201. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1c6bb690aeb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-plmmlw8m/dlib/dlib/cuda/gpu_data.cpp:201. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GXrCdzfPw-R"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZGDpU0Xff44"
   },
   "outputs": [],
   "source": [
    "# Read the image\n",
    "def read_image(video_filename,DIR):\n",
    "  \"\"\"Pass a filename and directory, return an image\n",
    "     Makes our full processing much easier later on\"\"\"\n",
    "  video_file = DIR + video_filename\n",
    "  cap = cv.VideoCapture(video_file)\n",
    "  success, image = cap.read()\n",
    "  image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "  cap.release()\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0ZCMwf7ff2l"
   },
   "outputs": [],
   "source": [
    "def face_location_and_coordinates(image):\n",
    "  \"\"\"Pass an image and return the location of a face, the landmarks dictionary,\n",
    "     and the full feature XY positions\n",
    "     We are most interested in the full_feature_list for graph generation\"\"\"\n",
    "  face_locations = face_recognition.face_locations(image)\n",
    "  if len(face_locations) ==1:\n",
    "    face_landmarks = face_recognition.face_landmarks(image)\n",
    "    full_feature_list = []\n",
    "    for cord in face_landmarks[0]:\n",
    "        full_feature_list.extend(face_landmarks[0].get(cord, \"\"))\n",
    "    return face_locations, face_landmarks, full_feature_list\n",
    "  else:\n",
    "    return [(0,0,0,0)], [(0,0,0,0)],[(0,0,0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BcVPxm1hvjO"
   },
   "outputs": [],
   "source": [
    "def graph_face(image):\n",
    "  \"\"\"Pass an image, return a graph of the facial landmarks of a person in the video\n",
    "     If there is no person detected, this will return zeros and will not be added to our collection\n",
    "     Working on handling the case where there are multiple people detected\"\"\"\n",
    "  locations, landmarks_list, full_feature_list = face_location_and_coordinates(image)\n",
    "  if locations == [(0, 0, 0, 0)]:\n",
    "    G=nx.Graph()\n",
    "    return G\n",
    "  else:\n",
    "    # Create individual graphs\n",
    "    graph_dict = {}\n",
    "    feature_tag = 0\n",
    "\n",
    "    for feature in list(landmarks_list[0].keys()):\n",
    "      # print(feature, feature_tag)\n",
    "      # should match list up next\n",
    "      total_nodes = len(landmarks_list[0][feature])\n",
    "      graph_dict[feature] = nx.complete_graph(n=total_nodes)\n",
    "      for current_node in range(total_nodes):\n",
    "        graph_dict[feature].nodes[current_node]['x']=float(landmarks_list[0][feature][current_node][0])\n",
    "        graph_dict[feature].nodes[current_node]['y']=float(landmarks_list[0][feature][current_node][1])\n",
    "        graph_dict[feature].nodes[current_node]['feature'] = int(feature_tag)\n",
    "      feature_tag +=1\n",
    "    graph_list = []\n",
    "    graph_list.append(graph_dict['chin'])          # tag=0\n",
    "    graph_list.append(graph_dict['left_eyebrow'])  # tag=1\n",
    "    graph_list.append(graph_dict['right_eyebrow']) # tag=2\n",
    "    graph_list.append(graph_dict['nose_bridge'])   # tag=3\n",
    "    graph_list.append(graph_dict['nose_tip'])      # tag=4\n",
    "    graph_list.append(graph_dict['left_eye'])      # tag=5\n",
    "    graph_list.append(graph_dict['right_eye'])     # tag=6\n",
    "    graph_list.append(graph_dict['top_lip'])       # tag=7\n",
    "    graph_list.append(graph_dict['bottom_lip'])    # tag=8\n",
    "\n",
    "\n",
    "    new_graph = nx.disjoint_union_all(graph_list)\n",
    "    for node_source in range(new_graph.number_of_nodes()):\n",
    "      for node_dest in range(new_graph.number_of_nodes()):\n",
    "        new_graph.add_edge(node_source,node_dest)\n",
    "    return new_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNgz6F5CB8lI"
   },
   "outputs": [],
   "source": [
    "def process_and_graph(video_filename, DIR, video_df):\n",
    "  \"\"\"Generate a label that designates the video as original or modified\"\"\"\n",
    "  image = read_image(video_filename=video_filename, DIR=DIR)\n",
    "  if video_df.loc[video_filename].label=='FAKE':\n",
    "    graph_label = 1\n",
    "  else:\n",
    "    graph_label = 0\n",
    "  graph = graph_face(image)\n",
    "  return graph, graph_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pK0L9c-Ic0k"
   },
   "outputs": [],
   "source": [
    "def add_graphs(DIR, label):\n",
    "  \"\"\"Take a directory containing all 'original' or all 'modified' videos,\n",
    "     create a graph and add to our full collection of graphs.\n",
    "     Modified and original videos will be shuffled later. \"\"\"\n",
    "  video_df = pd.DataFrame(index=(([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])))\n",
    "  video_df['label'] = label\n",
    "  video_list = video_df.index.to_series()\n",
    "  video_list = list(video_list)\n",
    "  for video in video_list:\n",
    "    # video = (f\"'{video}'\")\n",
    "    graph, graph_label = process_and_graph(video, DIR, video_df=video_df)\n",
    "    if len(graph) > 0:\n",
    "      full_graph_list.append(graph)\n",
    "      full_graph_labels.append(graph_label)\n",
    "\n",
    "  return full_graph_list, full_graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCToKMgUVTt_"
   },
   "outputs": [],
   "source": [
    "def write_text(text_filename, full_graph_list, full_graph_labels, number_of_graphs):\n",
    "  \"\"\"see https://github.com/muhanzhang/pytorch_DGCNN/tree/master/data for structure\n",
    "     Remember to change name after shuffling or you will overwrite data\"\"\"\n",
    "  file = open(text_filename,\"w\")\n",
    "  file.write(f'{number_of_graphs}\\n')\n",
    "  graph_index = 0\n",
    "  for graph in full_graph_list:\n",
    "    graph_label = full_graph_labels[graph_index]\n",
    "    graph_index +=1\n",
    "    file.write(f'{graph.number_of_nodes()} {graph_label}\\n')\n",
    "    for node in graph.nodes():\n",
    "      if graph.has_edge(node,node):\n",
    "        graph.remove_edge(node,node)\n",
    "      neighb_list = list(graph.neighbors(node))\n",
    "      file.write(f\"{graph.nodes[node]['feature']} {len(list(graph.neighbors(node)))} {' '.join(map(str, neighb_list))} {graph.nodes[node]['x']} {graph.nodes[node]['y']}, {graph.nodes[node]['feature']} \\n\")\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_17bXnORmtj"
   },
   "source": [
    "## Specify data, and create graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDQpc4tjRghg"
   },
   "source": [
    "### IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3ulEBS4LzNa"
   },
   "outputs": [],
   "source": [
    "### Very important to only define full_graph___ once!\n",
    "### We want to maintain our graph collection over multiple directory iterations\n",
    "### Our functions append these lists, and graph creation is a time consuming process at this scale\n",
    "### This is what we use to generate final output\n",
    "full_graph_list =[]\n",
    "full_graph_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDVhsjZyRO8k"
   },
   "outputs": [],
   "source": [
    "#Now specify the locations of all directories and labels\n",
    "full_graph_list,full_graph_labels = add_graphs(DIR='/content/drive/My Drive/deepfake/data_test/dataset_1/fake/', label = 'FAKE')\n",
    "full_graph_list,full_graph_labels = add_graphs(DIR='/content/drive/My Drive/deepfake/data_test/dataset_1/real/', label = 'REAL')\n",
    "\n",
    "# Get a final count to verify data additions\n",
    "number_of_graphs = len(full_graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KuWJ5rcDUz_6"
   },
   "outputs": [],
   "source": [
    "# Check all these to ensure we are ready to write to text\n",
    "# full_graph_list\n",
    "# full_graph_labels\n",
    "# number_of_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4QQXT7CTGmR"
   },
   "source": [
    "## Write Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poFxbOxK2lFs"
   },
   "outputs": [],
   "source": [
    "# Let's save the original unshuffled collection first\n",
    "write_text(text_filename='DFDC.txt', full_graph_list=full_graph_list, \n",
    "           full_graph_labels=full_graph_labels, number_of_graphs=number_of_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuFVpSf1UKy4"
   },
   "outputs": [],
   "source": [
    "# At this time, train/test splits are slightly cumbersome for this application in dgcnn\n",
    "# Choices are (specify index or take the last N graphs in the text file)\n",
    "# so we shuffle here (multiple times) to take different train/test splits\n",
    "\n",
    "# Now let's shuffle and save 10 times over\n",
    "for i in range(10):\n",
    "  c = list(zip(full_graph_list, full_graph_labels))\n",
    "  random.shuffle(c)\n",
    "  full_graph_list, full_graph_labels = zip(*c)\n",
    "  write_text(text_filename=f'DFDC_{i}.txt', full_graph_list=full_graph_list, \n",
    "           full_graph_labels=full_graph_labels, number_of_graphs=number_of_graphs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tNY4rZAVzXZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "dgcnn_graph_creation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
